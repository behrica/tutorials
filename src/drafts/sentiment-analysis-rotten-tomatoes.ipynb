{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(set! *print-length* 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(require '[clojupyter.misc.helper :as helper])\n",
    "(require '[clojupyter.misc.display :as display])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(helper/add-dependencies '[semantic-csv \"0.2.1-alpha1\"])\n",
    "(helper/add-dependencies '[hiccup-table \"0.2.0\"])\n",
    "(helper/add-dependencies '[metasoarous/oz \"1.5.6\"])\n",
    "(helper/add-dependencies '[de.find-method/tfidf \"0.1.0\"])\n",
    "(helper/add-dependencies '[com.zensols.nlp/parse \"0.1.6\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(require '[clojure.java.io :as io]\n",
    "            '[clojure-csv.core :as csv]\n",
    "            '[semantic-csv.core :as sc])\n",
    "(require 'hiccup.table)\n",
    "(require 'oz.core) \n",
    "(require 'oz.notebook.clojupyter)\n",
    "(require 'zensols.nlparse.parse\n",
    "          'zensols.nlparse.config\n",
    "          'zensols.nlparse.stopword\n",
    "          'tfidf.tfidf\n",
    "          'tfidf.freq\n",
    "          'tfidf.xf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read training data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next line reads the cvs file and stores as a sequnce-of-maps. So every elemnt in the sequence is a map, \n",
    "with one key per column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(def train \n",
    "(sc/slurp-csv \"data/sentiment-analysis-rotten-tomatoes/train.tsv\" :parser-opts {:delimiter \\tab}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the column names as taking the keys of the first row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(keys (first train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(defn display-seq-of-maps [seq-of-maps]\n",
    "   (let [ks (keys (first seq-of-maps))\n",
    "      mapping (map #(vector %1  %1) ks)]\n",
    "  (display/hiccup-html (hiccup.table/to-table1d seq-of-maps mapping))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the table nicely in the notebook, we convert it into hiccup, and render it to html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(display-seq-of-maps (take 5 train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(count train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have arround 155000 training cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the distribution among the 5 different values for \"Sentiment\", so how many do we have for each ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(frequencies (map :Sentiment train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explorative data analysis\n",
    "## Word clouds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word clouds allow a first glimpse into the text data, and we can see the distribution of words.\n",
    "First we do this for all texts, and then seperatedly for each senetiment value.\n",
    "\n",
    "The word is as larger as more often it apperas. Very common stopwords are excluded from a list.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use the oz library which uses vega/vega-lite specification to draw plots.\n",
    "The following is such a spec to draw word clouds given a sequence of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(defn word-cloud-spec-fromtext[texts]\n",
    "      {\"width\" 800\n",
    "       \"height\" 400,\n",
    "              \"padding\" 0\n",
    "              \"data\" [{\"name\" \"table\"\n",
    "                       \"values\" texts\n",
    "                           \"transform\" [{\"type\" \"countpattern\"\n",
    "                                         \"field\" \"data\"\n",
    "                                         \"case\" \"upper\"\n",
    "                                         \"pattern\" \"[\\\\w']{3,}\"\n",
    "                                         \"stopwords\" \"(i|me|my|myself|we|us|our|ours|ourselves|you|your|yours|yourself|yourselves|he|him|his|himself|she|her|hers|herself|it|its|itself|they|them|their|theirs|themselves|what|which|who|whom|whose|this|that|these|those|am|is|are|was|were|be|been|being|have|has|had|having|do|does|did|doing|will|would|should|can|could|ought|i'm|you're|he's|she's|it's|we're|they're|i've|you've|we've|they've|i'd|you'd|he'd|she'd|we'd|they'd|i'll|you'll|he'll|she'll|we'll|they'll|isn't|aren't|wasn't|weren't|hasn't|haven't|hadn't|doesn't|don't|didn't|won't|wouldn't|shan't|shouldn't|can't|cannot|couldn't|mustn't|let's|that's|who's|what's|here's|there's|when's|where's|why's|how's|a|an|the|and|but|if|or|because|as|until|while|of|at|by|for|with|about|against|between|into|through|during|before|after|above|below|to|from|up|upon|down|in|out|on|off|over|under|again|further|then|once|here|there|when|where|why|how|all|any|both|each|few|more|most|other|some|such|no|nor|not|only|own|same|so|than|too|very|say|says|said|shall)\"\n",
    "                                         }\n",
    "                                        {\"type\" \"formula\", \n",
    "                                        \"as\" \"angle\", \n",
    "                                        \"expr\" \"[-45, 0, 45][~~(random() * 3)]\"}\n",
    "                                        {\"type\" \"formula\", \n",
    "                                        \"as\" \"weight\", \n",
    "                                        \"expr\" \"if(datum.text=='VEGA', 600, 300)\"}]}]\n",
    "                                        \n",
    "                  \"scales\" [{\"name\" \"color\", \n",
    "                             \"type\" \"ordinal\", \n",
    "                             \"domain\" {\"data\" \"table\", \"field\" \"text\"}, \n",
    "                             \"range\" [\"#d5a928\" \"#652c90\" \"#939597\"]}]\n",
    "                  \"marks\" [{\"type\" \"text\", \n",
    "                            \"from\" {\"data\" \"table\"} \n",
    "                            \"encode\" {\"enter\" {\"text\" {\"field\" \"text\"}, \n",
    "                             \"align\" {\"value\" \"center\"}\n",
    "                             \"baseline\" {\"value\" \"alphabetic\"}\n",
    "                             \"fill\" {\"scale\" \"color\", \"field\" \"text\"}},\n",
    "                             \"update\" {\"fillOpacity\" {\"value\" 1}}, \n",
    "                             \"hover\" {\"fillOpacity\" {\"value\" 0.5}}}\n",
    "                             \n",
    "                    \"transform\" [{\"fontSizeRange\" [12 56]\n",
    "                                  \"fontWeight\" {\"field\" \"datum.weight\"},\n",
    "                                  \"padding\" 2\n",
    "                                  \"text\" {\"field\" \"text\"}\n",
    "                                   \"fontSize\" {\"field\" \"datum.count\"}\n",
    "                                   \"font\" \"Helvetica Neue, Arial\"\n",
    "                                   \"type\" \"wordcloud\", \"size\" [800 400]\n",
    "                                   \"rotate\" {\"field\" \"datum.angle\"}}]}]}\n",
    "    \n",
    "  \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(def sample-size 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(defn filtered-word-cloud [sentiment]\n",
    "    (oz.notebook.clojupyter/view! (word-cloud-spec-fromtext \n",
    "                                      (map #(:Phrase %) (take sample-size (filter #(= sentiment (:Sentiment %)) train))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All text word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(oz.notebook.clojupyter/view! (word-cloud-spec-fromtext (map  #(:Phrase %)  (take sample-size (shuffle train)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word clouds for each sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(filtered-word-cloud \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(filtered-word-cloud \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(filtered-word-cloud \"3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(filtered-word-cloud \"4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create the vocabulary, we first need to tokenize the text and get overall counts for each token.\n",
    "\n",
    "This can then be used to filter rare or very frequent tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(def tokenize-context\n",
    "  (->> (zensols.nlparse.config/create-parse-config :only-tokenize? true)\n",
    "       zensols.nlparse.config/create-context))\n",
    "\n",
    "\n",
    "(defn tokenize [s]\n",
    "  (zensols.nlparse.config/with-context tokenize-context\n",
    "   (->>(zensols.nlparse.parse/parse s)\n",
    "       (zensols.nlparse.parse/tokens)\n",
    "       (map :text)\n",
    "       )))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "(def tokens\n",
    "  (->>\n",
    "   (sequence\n",
    "    (comp\n",
    "     (map tokenize)\n",
    "     (map tfidf.freq/freq)\n",
    "     (filter #(not (empty? %)))\n",
    "     )\n",
    "    (map :Phrase (take 100 train)))\n",
    "   (apply merge-with +)\n",
    "   (#(sort-by second %))\n",
    "   reverse \n",
    "   ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(take 10 tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(display/hiccup-html (hiccup.table/to-table1d (take 50 tokens) [0 \"token\" 1 \"freq\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(+ 1 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Clojure",
   "language": "clojure",
   "name": "clojure"
  },
  "language_info": {
   "file_extension": ".clj",
   "mimetype": "text/x-clojure",
   "name": "clojure",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
